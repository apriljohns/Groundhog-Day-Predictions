---
title: "Groundhog Flex Dashboard"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r}
library(flexdashboard)
library(tidyverse)
library(reactable)
library(reactablefmtr)
library(htmltools)
library(scales)

# pull in raw data 
groundhogs_raw <- read_csv('../data/groundhogs_2025.csv')
predictions_raw <- read_csv('../data/predictions_2025.csv')
avg_daily_temp_df <- read_csv('../data/average_daily_temp_2025.csv')
```

Sidebar {.sidebar}
======================================================================

I was thinking it would be cute to have a little explanation/history of groundhog day as well as some navigation info

Map
======================================================================

Column {data-width=600}
-----------------------------------------------------------------------

### Map of US and Canada

### New England

Leader Board
============================================================================

Column {data-width=600}
-------------------------------------
    
### Leader Board

```{r}
# data frame with average winter temp (6 weeks preceding groundhog day)
avg_winter_temp_df <- avg_daily_temp_df %>% 
  filter(DOY %in% c(1:33, 357:366)) %>% 
  mutate(groundhog_winter_year = if_else(DOY %in% c(357:366), YEAR + 1, YEAR)) %>% 
  group_by(id, groundhog_winter_year) %>% 
  summarise(avg_winter_temp = mean(T2M))

# data frame with average temp for prediction interval (6 weeks following groundhog day)
avg_prediction_temp_df <- avg_daily_temp_df %>% 
  filter(DOY %in% c(34:75)) %>% 
  group_by(id, YEAR) %>% 
  summarise(avg_prediction_temp = mean(T2M))

# data frame with average spring temp (6 weeks following prediction interval -- 6-12 weeks following groundhog day)
avg_spring_temp_df <- avg_daily_temp_df %>% 
  filter(DOY %in% c(75:116)) %>% 
  group_by(id, YEAR) %>% 
  summarise(avg_spring_temp = mean(T2M))
  
# join dataframes together, then compare which season prediction interval is closest to 
prediction_eval_df <- predictions_raw %>% 
  filter(year > 1980) %>% 
  filter(!is.na(shadow)) %>% 
  left_join(avg_winter_temp_df, by = c('id', 'year' = 'groundhog_winter_year')) %>% 
  left_join(avg_prediction_temp_df, by = c('id', 'year' = 'YEAR')) %>% 
  left_join(avg_spring_temp_df, by = c('id', 'year' = 'YEAR')) %>% 
  mutate(delta_winter = abs(avg_winter_temp - avg_prediction_temp)) %>% 
  mutate(delta_spring = abs(avg_spring_temp - avg_prediction_temp)) %>% 
  mutate(six_more_weeks = delta_winter < delta_spring) %>% 
  mutate(is_correct = if_else(shadow & six_more_weeks, TRUE, FALSE))

# make a separate leaderboard dataframe, compute accuracy 
leaderboard_df <- prediction_eval_df %>% 
  group_by(id) %>% 
  summarize(num_predictions = n(), 
            total_correct = sum(is_correct),
            accuracy = sum(is_correct)/n(),
            start_year = min(year)) %>% 
  arrange(desc(accuracy)) %>% 
  mutate(rank = row_number()) %>% 
  left_join(groundhogs_raw, by = 'id') 
  
# use reactable to make interactive leaderboard 
leaderboard_df %>% 
  select(rank, name, accuracy, type, city, region, country) %>%
  reactable(theme = fivethirtyeight(),
            defaultColDef = colDef(align = "center",
                                   headerStyle = list(background = "lightblue")),
            columns = list(name = colDef(name = 'Name',
                                         cell = function(value, index) {
                                           url <- leaderboard_df$source[index]
                                           tags$a(href = url, value)
                                         }),
                           accuracy = colDef(name = "Accuracy",
                                                 cell = data_bars(., text_position = 'above',
                                                                  number_fmt = percent_format(accuracy = 0.1),
                                                                  fill_color = 'steelblue', background = 'lightgrey')),
                           region = colDef(name = "State/Province"),
                           url = colDef(show = FALSE)),
            onClick = 'expand',
            details = function(index){
              sub_table <- leaderboard_df %>% 
                slice(index) %>% 
                select(image, description, num_predictions, start_year, source)
              reactable(sub_table,
                        defaultColDef = colDef(headerVAlign = 'bottom'),
                        columns = list(image = colDef(name = 'Photo',
                                                      cell = function(value) {
                                                        tags$img(src = value,
                                                                 width = 400)
                                                        },
                                                      width = 420),
                                       description = colDef(name = "Description",
                                                            width = 400),
                                       source = colDef(name = 'Source',
                                                       cell = function(value, index) {
                                                         url <- leaderboard_df$source[index]
                                                         tags$a(href = url, value)
                                                         }),
                                       num_predictions = colDef(name = "Total Number of Predictions"),
                                       start_year = colDef(name = "First Year Prognosticating")))
            },
            height = 800,
            #width = 1400,
            highlight = TRUE,
            defaultPageSize = 15,
            filterable = TRUE,
            searchable = TRUE)
```


Seasonal Consistency and Prognosticator Accuracy
============================================================================

Column {data-width=600}
-------------------------------------
    
### Seasonal Consistency and Prognosticator Accuracy

```{r}
## Koppen Zones are not being used, but using these dfs

#read in koppen stand alone CSV generated by standalone scrip
koppen_legit <- read_csv("../data/koppen_zones.csv")

#join koppen_legit with the groundhogs

a <- left_join(x = groundhogs_raw, y = koppen_legit, by = "id")

#join with the prediction eval df

b <- left_join(x = prediction_eval_df, a, by = "id")

#get what is needed for the plot from this unholy mess of a df

c <- b %>% 
  select(climate_type, name, is_correct, six_more_weeks)


#summarize accuracy, consistency of 6 more weeks winter according to model
#and adjusted accuracy

accuracy_plot_data <- c %>%
  group_by(name) %>% 
  summarise(accuracy = sum(is_correct, na.rm = TRUE)/n(),
            consistency = abs(0.5 - sum(six_more_weeks)/n()),
            adj_accuracy = accuracy * (1 - consistency)) %>% 
  arrange(consistency) %>% #ascending order for consistency
  ungroup()

ranks <- c(1:88) #vector for ranks and bind below

accuracy_plot_data_ranked <- cbind(accuracy_plot_data, ranks)

#determine cuts for quartiles
consist_quartiles <- accuracy_plot_data_ranked %>% pull(consistency) %>% 
  quantile()

#consist_quartiles (cuts for quartiles)
#        0%        25%        50%        75%       100% 
#0.02941176 0.32121212 0.40909091 0.45454545 0.50000000 

#apply quartile cuts to data
foo <- accuracy_plot_data_ranked %>% 
  mutate(quartile = cut(consistency,
          breaks=c(0.02941176, 0.32121212, 0.40909091, 0.45454545, 0.5), 
          include.lowest=TRUE, 
          labels=c("Quartile 1", "Quartile 2", "Quartile 3", "Quartile 4"), 
          ordered_result = TRUE))

#Divide into consistency quartiles - these will just show
#accuracy and adjusted accuracy
#Do scatterplot of accuracy vs consistency

#tidy the data. Koppen zones are no longer needed.


pl_accuracy_plot_data <- foo %>%
  pivot_longer(cols = c(accuracy, consistency, adj_accuracy),
               names_to = "prognosticator_and_climate_parameter",
               values_to = "coefficients")

# Separate the datasets into each parameter

df_accuracy <- pl_accuracy_plot_data %>%
  filter(prognosticator_and_climate_parameter == "accuracy")

df_adj_accuracy <- pl_accuracy_plot_data %>%
  filter(prognosticator_and_climate_parameter == "adj_accuracy")

# Create the plot for the quartiles
quartile_plot <- ggplot() +
  geom_col(data = df_accuracy,
           aes(x = reorder(name, -coefficients),
               y = coefficients, fill = prognosticator_and_climate_parameter),
           position = position_nudge(x = 0), width = 0.35) +
  geom_col(data = df_adj_accuracy,
           aes(x = name, y = coefficients, fill = prognosticator_and_climate_parameter),
           position = position_nudge(x = 0.0), width = 0.35) +
  facet_wrap(~ quartile, scales = "free_x") +
  theme(strip.text.y.left = element_text(angle = 0)) +
  labs(
    title = "Consistency quartiles",
    x = " ",
    y = "Proportion\n\n",
    fill = "Metric"
  ) +
  scale_fill_discrete(labels = c("Accuracy", "Adjusted Accuracy")) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = c(0.5, -.20), legend.direction = "horizontal")


#fit a linear regression for accuracy by consistency and get the 
#R-squared to plot in the figure

# foo_lm <- lm(foo$accuracy ~ foo$consistency)
# summary(foo_lm)
# 
# Call:
# lm(formula = foo$accuracy ~ foo$consistency)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -0.4087 -0.1305 -0.0048  0.1499  0.5375 
# 
# Coefficients:
#                 Estimate Std. Error t value Pr(>|t|)    
# (Intercept)      0.25813    0.06633   3.891 0.000196 ***
# foo$consistency  0.30111    0.17067   1.764 0.081239 .  
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.1996 on 86 degrees of freedom
# Multiple R-squared:  0.03493,	Adjusted R-squared:  0.02371 
# F-statistic: 3.113 on 1 and 86 DF,  p-value: 0.08124

#Create the plot and for consistency vs accuracy
consist_plot <- foo %>% ggplot(aes(x = consistency, y = accuracy, colour = name)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, colour = "black") +
  theme(legend.position = "none") +
  annotate("text", x = .13, y = .33, label = "italic(R)^2 == .035",
           parse = TRUE, size = 4, angle = 10.5) +
  labs(x = "Early Spring Consistency\n at Prognoticator Location",
       y = "Pronosticator Accuracy") +
  theme(axis.title.x = element_text(vjust = 25))
  
  

library(patchwork)

#bring plots together
combined_plot <- quartile_plot + 
  (plot_spacer() + consist_plot + plot_spacer() + 
   plot_layout(widths = c(0.1, 1, 0.1))) + 
  plot_layout(widths = c(2, 1))


print(combined_plot)



```




Documentation
============================================================================

Things to document:

Data sources (weather, groundhogs, packages?)

Spring onset calcs

Phylo info
