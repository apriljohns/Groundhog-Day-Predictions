---
title: "Groundhog Day Prognostication"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
css: ../styling/styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r}
library(flexdashboard)
library(tidyverse)
library(reactable)
library(reactablefmtr)
library(htmltools)
library(htmlwidgets)
library(scales)
library(knitr)

# pull in raw data 
groundhogs_raw <- read_csv('../data/groundhogs_2025.csv')
predictions_raw <- read_csv('../data/predictions_2025.csv')
avg_daily_temp_df <- read_csv('../data/average_daily_temp_2025.csv')
```

Sidebar {.sidebar}
======================================================================

Since 1887, a groundhog named Punxsutawney Phil has emerged from his burrow on February 2nd to look for his shadow. If he sees it, he retreats to his burrow, indicating another six weeks of winter. Since then, many other Groundhog Day prognosticators have emerged, all claiming to predict the weather.

The records of 88 prognosticators were aggregated from <https://groundhog-day.com/>. While many prognosticators are groundhogs (*Marmota monax*), 17 other species are also represented. Previous studies have evaluated the overall accuracy of Groundhog Day prognosticators, but no one has compared groundhogs to non-groundhogs.  Explore the dashboard to see the distribution of prognosticators, the overall performance of individuals, and the accuracy of prognosticators when adjusted to their climate stability. 


Map
======================================================================

Column {data-width=600}
-----------------------------------------------------------------------

### 

```{r}
library(sf)
library(leaflet)
library(leaflegend)
library(leaflet.extras)

groundhog_phylo <- read_csv("../data/groundhog_phylo.csv") #csv with status (alive, dead, never alive) and sci name
groundhog_range <- st_read("../data/shape_files/groundhog_range.shp", quiet = TRUE) #shapefile of groundhog range

groundhog_map <- groundhogs_raw %>% #building the data frame for the leaflet
  left_join(groundhog_phylo) %>% #adding the status and sci name
  mutate(is_groundhog = sci_name == "Marmota monax", #changing the type to groundhog even if they are dead/inannimate
         alive_gh = paste0(is_groundhog, ", ", alive), #creating a column combining status and type
         alive_gh = trimws(alive_gh)) %>%
  rename("lon" = longitude, #renameing lon and lat to make using leaflet easier
         "lat" = latitude)

gh_icons <- awesomeIconList( #making the awesome icon list
  "TRUE, yes"    = makeAwesomeIcon(
    icon = "paw",
    markerColor = "darkpurple",
    library = "fa"),
  "FALSE, yes"   = makeAwesomeIcon(
    icon = "paw",
    markerColor = "darkgreen",
    library = "fa"),
  "TRUE, no"     = makeAwesomeIcon(
    icon = "times",
    markerColor = "darkpurple",
    library = "fa"),
  "FALSE, no"    = makeAwesomeIcon(
    icon = "times",
    markerColor = "darkgreen",
    library = "fa"),
  "TRUE, never"  = makeAwesomeIcon(
    icon = "cube",
    markerColor = "darkpurple",
    library = "fa"),
  "FALSE, never" = makeAwesomeIcon(
    icon = "cube",
    markerColor = "darkgreen",
    library = "fa")
)

status_icons <- awesomeIconList( #making a list just for status so I can have two legends, one for status and one for type
  Alive = makeAwesomeIcon(
    icon = "heart",
    markerColor = "cadetblue",
    library = "fa"
  ),
  Dead = makeAwesomeIcon(
    icon = "times",
    markerColor = "cadetblue",
    library = "fa"
  ),
  Inanimate = makeAwesomeIcon(
    icon = "cube",
    markerColor = "cadetblue",
    library = "fa"
  )
)

type_icons <- awesomeIconList( #type list
  Groundhog = makeAwesomeIcon(
    icon = "circle",
    markerColor = "darkpurple",
    iconColor = "transparent",
    library = "fa"
  ),
  `Not a groundhog` = makeAwesomeIcon(
    icon = "circle",
    markerColor = "darkgreen",
    iconColor = "transparent",
    library = "fa"
  )
)


leaflet(groundhog_map) %>% #making the leaflet
  addTiles() %>%
  addPolygons( #adding the range from the shape file
    data = groundhog_range,
    fillColor = '#EFD6C1',
    fillOpacity = 0.3,
    color = '#8A1A6B',
    weight = 1
  ) %>%
  addAwesomeMarkers( #adding the groundhogs
    lng   = ~lon,
    lat   = ~lat,
    icon  = ~gh_icons[alive_gh],
    label = ~name
  )  %>%
  addLegendAwesomeIcon( #adding the status legend
    iconSet = status_icons,
    title = "Status"
  ) %>%
  addLegendAwesomeIcon( #adding the type legend
    iconSet = type_icons,
    title = "Type",
    position = "bottomleft"
  )


```


Leaderboard
============================================================================

Column {data-width=600}
-------------------------------------
    
### {#leaderboard}

```{r}
# data frame with average winter temp (6 weeks preceding groundhog day)
avg_winter_temp_df <- avg_daily_temp_df %>% 
  filter(DOY %in% c(1:33, 357:366)) %>% 
  mutate(groundhog_winter_year = if_else(DOY %in% c(357:366), YEAR + 1, YEAR)) %>% 
  group_by(id, groundhog_winter_year) %>% 
  summarise(avg_winter_temp = mean(T2M))

# data frame with average temp for prediction interval (6 weeks following groundhog day)
avg_prediction_temp_df <- avg_daily_temp_df %>% 
  filter(DOY %in% c(34:75)) %>% 
  group_by(id, YEAR) %>% 
  summarise(avg_prediction_temp = mean(T2M))

# data frame with average spring temp (6 weeks following prediction interval -- 6-12 weeks following groundhog day)
avg_spring_temp_df <- avg_daily_temp_df %>% 
  filter(DOY %in% c(75:116)) %>% 
  group_by(id, YEAR) %>% 
  summarise(avg_spring_temp = mean(T2M))
  
# join dataframes together, then compare which season prediction interval is closest to 
prediction_eval_df <- predictions_raw %>% 
  filter(year > 1980) %>% 
  filter(!is.na(shadow)) %>% 
  left_join(avg_winter_temp_df, by = c('id', 'year' = 'groundhog_winter_year')) %>% 
  left_join(avg_prediction_temp_df, by = c('id', 'year' = 'YEAR')) %>% 
  left_join(avg_spring_temp_df, by = c('id', 'year' = 'YEAR')) %>% 
  mutate(delta_winter = abs(avg_winter_temp - avg_prediction_temp)) %>% 
  mutate(delta_spring = abs(avg_spring_temp - avg_prediction_temp)) %>% 
  mutate(six_more_weeks = delta_winter < delta_spring) %>% 
  mutate(is_correct = if_else(shadow & six_more_weeks, TRUE, FALSE))

# make a separate leaderboard dataframe, compute accuracy 
leaderboard_df <- prediction_eval_df %>% 
  group_by(id) %>% 
  summarize(num_predictions = n(), 
            total_correct = sum(is_correct),
            accuracy = sum(is_correct)/n(),
            start_year = min(year)) %>% 
  arrange(desc(accuracy)) %>% 
  mutate(rank = row_number()) %>% 
  left_join(groundhogs_raw, by = 'id') %>% 
  mutate(groundhog_day_profile = paste0('https://groundhog-day.com/groundhogs/', slug))
  
# use reactable to make interactive leaderboard 
leaderboard_df %>% 
  select(rank, name, accuracy, type, city, region, country) %>%
  reactable(theme = fivethirtyeight(),
            defaultColDef = colDef(align = "center",
                                   headerStyle = list(background = "#565A0480",
                                                      fontSize = "15px")),
            columns = list(name = colDef(name = 'Name',
                                         cell = function(value, index) {
                                           url <- leaderboard_df$groundhog_day_profile[index]
                                           tags$a(href = url, value)
                                         }),
                           accuracy = colDef(name = "Accuracy",
                                                 cell = data_bars(., text_position = 'above',
                                                                  number_fmt = percent_format(accuracy = 0.1),
                                                                  fill_color = '#8A1A6B', background = '#EFD6C1')),
                           region = colDef(name = "State/Province",
                                           width = 150),
                           rank = colDef(minWidth = 50),
                           url = colDef(show = FALSE)),
            onClick = 'expand',
            details = function(index){
              
              sub_table <- leaderboard_df %>% 
                slice(index) %>% 
                select(image, description, num_predictions, start_year, source) 
              
              reactable(sub_table,
                        style = list(opacity = 0.99),
                        defaultColDef = colDef(headerVAlign = 'bottom',
                                               headerStyle = list(background = "#FFFFFF80",
                                                                  textAlign = "left",
                                                                  overflowWrap = "normal")),
                        columns = list(image = colDef(name = 'Photo',
                                                      cell = function(value) {
                                                        tags$img(src = value,
                                                                 width = 300)
                                                        },
                                                      width = 320),
                                       description = colDef(name = "Description",
                                                            minWidth = 240,
                                                            cell = function(value, index) {
                                                              url <- sub_table$source[index]
                                                              tagList(value, tags$br(), tags$br(), tags$a("Source", href = url))}),
                                       num_predictions = colDef(name = "Total Predictions",
                                                                minWidth = 90,
                                                                align = "left"),
                                       start_year = colDef(name = "First Year Prognosticating",
                                                           minWidth = 120,
                                                           align = "left"),
                                       source = colDef(show = FALSE)))
            },
            highlight = TRUE,
            defaultPageSize = 15,
            filterable = TRUE,
            searchable = TRUE,
            class = "leaderboard-rt",
            rowClass = "my-row") %>% 
  add_title("Groundhog Day Leaderboard", font_size = 30) %>% 
  add_subtitle("Prognosticator Ranks by Overall Weather Prediction Accuracy", font_size = 20, font_color = 'darkgrey')
```


Seasonal Consistency
============================================================================

Column {data-width=600}
-------------------------------------
    
### {#consistency}

```{r}
library(plotly)
## Koppen Zones are not being used, but using these dfs

#read in koppen stand alone CSV generated by standalone scrip
koppen_legit <- read_csv("../data/koppen_zones.csv")

#join koppen_legit with the groundhogs

a <- left_join(x = groundhogs_raw, y = koppen_legit, by = "id")

#join with the prediction eval df

b <- left_join(x = prediction_eval_df, a, by = "id")

#get what is needed for the plot from this unholy mess of a df

c <- b %>% 
  select(climate_type, name, is_correct, six_more_weeks)


#summarize accuracy, consistency of 6 more weeks winter according to model
#and adjusted accuracy

accuracy_plot_data <- c %>%
  group_by(name) %>% 
  summarise(accuracy = sum(is_correct, na.rm = TRUE)/n(),
            consistency = abs(0.5 - sum(six_more_weeks)/n()),
            adj_accuracy = accuracy * (1 - consistency)) %>% 
  arrange(consistency) %>% #ascending order for consistency
  ungroup()

ranks <- c(1:88) #vector for ranks and bind below

accuracy_plot_data_ranked <- cbind(accuracy_plot_data, ranks)

#determine cuts for quartiles
consist_quartiles <- accuracy_plot_data_ranked %>% pull(consistency) %>% 
  quantile()

#consist_quartiles (cuts for quartiles)
#        0%        25%        50%        75%       100% 
#0.02941176 0.32121212 0.40909091 0.45454545 0.50000000 

#apply quartile cuts to data
foo <- accuracy_plot_data_ranked %>% 
  mutate(quartile = cut(consistency,
          breaks=c(0.02941176, 0.32121212, 0.40909091, 0.45454545, 0.5), 
          include.lowest=TRUE, 
          labels=c("Quartile 1", "Quartile 2", "Quartile 3", "Quartile 4"), 
          ordered_result = TRUE))

#Divide into consistency quartiles - these will just show
#accuracy and adjusted accuracy
#Do scatterplot of accuracy vs consistency

#tidy the data. Koppen zones are no longer needed.


pl_accuracy_plot_data <- foo %>%
  pivot_longer(cols = c(accuracy, consistency, adj_accuracy),
               names_to = "prognosticator_and_climate_parameter",
               values_to = "coefficients")

# Separate the datasets into each parameter

df_accuracy <- pl_accuracy_plot_data %>%
  filter(prognosticator_and_climate_parameter == "accuracy") %>% 
  mutate(prognosticator_and_climate_parameter = factor("Overall Accuracy", levels = c("Overall Accuracy", "Corrected Accuracy")))

df_adj_accuracy <- pl_accuracy_plot_data %>%
  filter(prognosticator_and_climate_parameter == "adj_accuracy") %>% 
  mutate(prognosticator_and_climate_parameter = factor("Corrected Accuracy", levels = c("Overall Accuracy", "Corrected Accuracy")))

# Create the plot for the quartiles
quartile_plot <- ggplot() +
  geom_col(data = df_accuracy,
           aes(x = reorder(name, -coefficients),
               y = coefficients, fill = prognosticator_and_climate_parameter,
               text = paste0("Name: ", name, '\n', "Accuracy: ", round(coefficients*100, 1), "%")),
           position = position_nudge(x = 0), width = 0.35) +
  geom_col(data = df_adj_accuracy,
           aes(x = name, y = coefficients, fill = prognosticator_and_climate_parameter,
               text = paste0("Name: ", name, '\n', "Corrected Accuracy: ", round(coefficients*100, 1), "%")),
           position = position_nudge(x = 0.0), width = 0.35) +
  facet_wrap(~ quartile, scales = "free_x") +
  theme_minimal() +
  labs(
    x = " ",
    y = "Pronosticator Accuracy",
    fill = "Metric",
    caption = 'test caption'
  ) +
  scale_fill_manual(values = c("Overall Accuracy" = "#b2b79dff", "Corrected Accuracy" = "#646E3BFF")) +
  theme(
    axis.text.x = element_text(size = 8, face = "bold", angle = 45, hjust = 1),
    axis.text.y = element_text(size = 8),
    axis.title.y = element_text(size = 11, margin = ggplot2::margin(r = 40), face = "bold"),
    legend.position = c(0.5, -.25), 
    legend.direction = "horizontal",
    legend.text = element_text(size = 8),
    plot.title = element_text(face = "bold"),
    plot.margin = ggplot2::margin(t = 0, r = 80, b = 0, l = 80)) 




#fit a linear regression for accuracy by consistency and get the 
#R-squared to plot in the figure

# foo_lm <- lm(foo$accuracy ~ foo$consistency)
# summary(foo_lm)
# 
# Call:
# lm(formula = foo$accuracy ~ foo$consistency)
# 
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -0.4087 -0.1305 -0.0048  0.1499  0.5375 
# 
# Coefficients:
#                 Estimate Std. Error t value Pr(>|t|)    
# (Intercept)      0.25813    0.06633   3.891 0.000196 ***
# foo$consistency  0.30111    0.17067   1.764 0.081239 .  
# ---
# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# 
# Residual standard error: 0.1996 on 86 degrees of freedom
# Multiple R-squared:  0.03493,	Adjusted R-squared:  0.02371 
# F-statistic: 3.113 on 1 and 86 DF,  p-value: 0.08124

#Create the plot and for consistency vs accuracy
consist_plot <- foo %>% ggplot(aes(x = consistency, y = accuracy, colour = quartile)) +
  geom_point(aes(text = paste0("Name: ", name, '\n', "Consistency: ", round(consistency, 2), '\n', "Accuracy: ", round(accuracy*100, 1), "%"))) +
  geom_smooth(method = "lm", se = TRUE, colour = "black", linewidth = .3) +
  annotate("text", x = .13, y = .35, label = "<i>R</i><sup>2</sup> = 0.035",
           parse = TRUE, size = 3, angle = 7.7) +
  labs(x = "Climate Consistency Index",
       y = "Pronosticator Accuracy\n\n",
       colour = '') +
  theme_minimal() + 
  theme(axis.title.x = element_text(size = 11, vjust = 14, face = "bold"),
        axis.title.y = element_text(size = 11, margin = ggplot2::margin(r = 80), face = "bold"),
        axis.text.y = element_text(margin = ggplot2::margin(r = 20)),
        legend.position = c(0.5, -0.2), legend.direction = "horizontal",
        legend.text = element_text(size = 8)) +
  theme(legend.title = element_blank(),
        plot.title = element_text(face = "bold"),
    plot.margin = ggplot2::margin(t = 0, r = 80, b = 0, l = 80)) +
  scale_colour_manual(values = c("Quartile 1" = "#854B5BFF",
                                 "Quartile 2" = "#C3A53CFF",
                                 "Quartile 3" = "#646E3BFF",
                                 "Quartile 4" = "#508EA2FF"))


#library(patchwork)

#reduce margin of consist_plot

#combined_plot <- consist_plot / quartile_plot
 

#bring plots together

#print(combined_plot)

```

<h4 style = "font-size:24px; text-align:center;"><b>Climate Consistency vs. Prognosticator Prediction Accuracy</b></h4>
```{r}
div(
  style = "height:75%; margin: 0 auto;",
  ggplotly(consist_plot, tooltip = "text") %>% 
    layout(legend = list(orientation = "v",
                         xanchor = "center",
                         x = 1.02,
                         y = 0.5))
)

```
<h3 style = "font-size:16px; text-align:center;"><i>Consistency indices: 0 → least consistent, 0.5 → most consistent</i></h3>
<br></br>

---

<br></br>
<h4 style = "font-size:24px; text-align:center;"><b>Prediction Accuracy and Adjusted Accuracy Across Climate Consistency Quartiles</b></h4>

```{r}
div(
  style = "height:75%; margin: 0 auto;",
  ggplotly(quartile_plot, tooltip = "text")
)

```
<h3 style = "font-size:16px; text-align:center;"><i>Consistency quartiles: Q1 → least consistent, Q4 → most consistent</i></h3>
<br></br>
<br></br>

Documentation {#documentation}
============================================================================
Row
-------------------------------------
### 

---

<h4 style = "font-size:20px; text-align:center;"><b> Workflow and Analysis </b></h4>

---

***Mapping Groundhog Day Prognosticators***

The locations of the prognosticators were added to an interactive leaflet map using the longitude and latitude values provided in the original dataset. Awesome icons, a marker that is built into the base leaflet package, was used to add markers with icons indicating the status of the prognosticator and colors indicating the type. Legends were added via [leaflegend](https://cran.r-project.org/package=leaflegend).

***Mapping Groundhog Habitat Range***

The groundhog habitat range shape file was obtained from the International Union for the Conservatio 

***Retrieving Historical Weather Data***

Using latitude and longitude values provided in the original groundhog dataset, we queried NASA POWER data for each groundhog location. For each location, we collected average daily surface temperature (T2M) between 01/01/1981 and 07/01/2025. The resulting dataset was then written to a CSV file and saved in the project’s *data* directory. This allowed the analysis to remain reproducible while avoiding the need to re-query the *nasapower* database each time the script was run. 

***Assessing Prediction Accuracy***

Each groundhog prediction falls into one of two categories: 

1. Sees shadow, predicting *six more weeks of winter*
2. Does not see shadow, predicting an *early spring*

To evaluate prediction accuracy, we divided the seasonal temperature data into three six-week windows:

1. Winter baseline: the six weeks preceding Groundhog Day
2. Prediction window: the six weeks following Groundhog Day
3. Spring baseline: the six-week period after the prediction window

For each window, we calculated the mean daily temperature. We then determined whether the observed temperature during the prediction window was more similar to winter or spring conditions by comparing its distance from the winter and spring averages. A prediction was classified as correct if the groundhog’s prediction matched the observed weather conditions.

***Comparing Prognosticator Accuracy***

To compare performance across prognosticators, we calculated overall accuracy as the proportion of correct predictions out of total predictions made by each groundhog. Prognosticators were then ranked by this accuracy metric. These results were displayed in an interactive leaderboard, allowing users to explore accuracy rankings alongside summarizing information about each prognosticator, including details such as location, number of years prognosticating, and links to their profiles. 

***Assessing Seasonal Consistency***

An easy gig for a professional prognosticator would be to prognosticate in a locale with
very consistent climate. We're lookin' at you, "Dunkirk Dave!" To quantify weather consistency,
we looked at the proportion of times during each prognosticator's career that there were
six more weeks of winter according to our model. Therefore, a maximally inconsistent climate
pattern would be 0.5 (half the time there are six more weeks, and half the time there was
early spring). We took the difference of this value from one (1 minus inconsistency)
to state the Climate Consistency Index.

***Correcting Prognosticator Accuracy***

To assess the accuracy of prognosticators in the context of the advantage that climate
consistency confers, we calculated a corrected accuracy by multiplying the climate 
consistency index by accuracy.
$$
A_{corrected} = Accuracy * [1 - |0.5 - (\sum\limits_{i=1}^{n} i \div \sum\limits_{j=1}^n j) |]
$$


$$
\begin{equation}
\text{Where } i = \text{ a year saw shadow and } \\ j = \text{ a year a prediction was rendered}
\end{equation}
$$

<h4 style = "font-size:20px; text-align:center;"><b> Data Sources </b></h4>

---

***Original Data:***
[Tidy Tuesday](https://github.com/rfordatascience/tidytuesday/blob/main/data/2024/2024-01-30/readme.md)

***Prognosticators and Predictions:***
[Groundhog Day Website](https://groundhog-day.com/)

***Weather Data API:***
[NASA POWER](https://power.larc.nasa.gov/parameters/)

***Groundhog Habitat Range:***
IUCN. 2025. The IUCN Red List of Threatened Species. Version 2025-2. <https://www.iucnredlist.org>. Accessed on December 7, 2025.

Row 
-------------------------------------
### 

---

<h4 style = "font-size:20px; text-align:center;"><b> Packages Highlight </b></h4>

---

***nasapower***

The [nasapower](https://docs.ropensci.org/nasapower/) package provides an interface for easily accessing NASA POWER (Prediction Of Worldwide Energy Resource) global climatology and meteorology data directly within R and in a tidy format. We used this package to retrieve daily average surface air temperature at 2 meters above the surface (T2M) for each prognosticator location. This particular data set has a spatial resolution of 0.5 × 0.625 degrees latitude × longitude, an hourly temporal resolution, and historical coverage dating back to January 1st, 1981. This package allowed us to link historical temperature data for each prognosticator's geographic location, which facilitated our assessment of each Groundhog Day prediction. 

***reactable*** and ***reactablefmtr***

The [reactable](https://glin.github.io/reactable/index.html) package was used to render interactive tables within the R Markdown flexdashboard. It provides a suite of built-in table features, such as searching and filtering rows, nesting data with expandable rows, and customizing the display. The [reactablefmtr](https://kcuilla.github.io/reactablefmtr/index.html) package further extends this functionality to enable additional styling and table features, including embedded images and displaying subplots in rows. These packages were used extensively to create the Groundhog Leaderboard, allowing users to interactively explore and compare Groundhog Day prognosticators. 

***htmltools***

The [htmltools](https://cran.r-project.org/web/packages/htmltools/refman/htmltools.html#htmltools-package) package was used to further customize the Groundhog leaderboard beyond what was natively supported by existing R packages. By embedding custom HTML elements within table itself, we were able to control layout and behavior at a finer level. For example, htmltools was used to generate hyperlinked prognosticator names, allowing users to click directly from the leaderboard to external profile pages.

***leaflet***

The [leaflet](https://cran.r-project.org/package=leaflet) package was used to create an interactive map of Groundhog Day prognosticators. The function addAwesomeIcons was used to create icons for each prognosticator where the shape referenced the status of the prognosticator (alive, dead, or never alive/inanimate) and the color referenced the type of prognosticator (groundhog or non-groundhog). The icons are from the [Font Awesome 4.7 library](https://fontawesome.com/v4/icons/), which are included in leaflet and accessable via addAwesomeIcons.

---

<h4 style = "font-size:20px; text-align:center;"><b> References </b></h4>

---

**Citations for Used Packages:**
```{r}
format(citation("flexdashboard"), style = "text")
format(citation("tidyverse"), style = "text")
format(citation("nasapower"), style = "text")
format(citation("reactable"), style = "text")
format(citation("reactablefmtr"), style = "text")
format(citation("htmltools"), style = "text")
format(citation("htmlwidgets"), style = "text")
format(citation("scales"), style = "text")
format(citation("knitr"), style = "text")
format(citation("sf"), style = "text")
format(citation("leaflet"), style = "text")
format(citation("leaflegend"), style = "text")
format(citation("leaflet.extras"), style = "text")
```